{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj8W_RXoajYt"
      },
      "outputs": [],
      "source": [
        "\"\"\"\"Theoretical Questions\n",
        "\n",
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "Logistic Regression is used for classification problems (predicting categorical outcomes like 0/1, Yes/No).\n",
        "\n",
        "Linear Regression predicts a continuous numeric value.\n",
        "\n",
        "In Logistic Regression, the output is probabilistic (between 0 and 1), whereas in Linear Regression it can be any real number.\n",
        "\n",
        "2. What is the mathematical equation of Logistic Regression?\n",
        "The logistic regression equation is:\n",
        "P(y=1‚à£x)=œÉ(z)= 1/1+e ‚àíz\n",
        "where\n",
        "ùëß\n",
        "=\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ1ùë•1+ùõΩ2ùë•2+...+ùõΩùëõùë•ùëõ\n",
        "\n",
        "3. Why do we use the Sigmoid function in Logistic Regression?\n",
        "The sigmoid function squashes input values into the range (0, 1), making it suitable for modeling probabilities.\n",
        "\n",
        "It ensures that the output can be interpreted as a probability.\n",
        "\n",
        "4. What is the cost function of Logistic Regression?\n",
        "The cost function is the Log Loss (Binary Cross-Entropy):\n",
        "J(Œ∏)=‚àí m/1\n",
        "i=1‚àëm\n",
        "(y\n",
        "(i)\n",
        " log(\n",
        "y\n",
        "^\n",
        "(i)\n",
        " )+(1‚àíy\n",
        "(i)\n",
        " )log(1‚àí\n",
        "y\n",
        "^\n",
        "(i)\n",
        " ))\n",
        "where\n",
        "ùë¶\n",
        "^\n",
        "y\n",
        "^\n",
        "‚Äã\n",
        "  is the predicted probability.\n",
        "\n",
        "5. What is Regularization in Logistic Regression? Why is it needed?\n",
        "Regularization adds a penalty to the cost function to prevent overfitting.\n",
        "\n",
        "It discourages the model from fitting noise by keeping model parameters (weights) small.\n",
        "\n",
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        "Lasso (L1 Regularization): Shrinks some coefficients to zero ‚Äî good for feature selection.\n",
        "\n",
        "Ridge (L2 Regularization): Shrinks coefficients smoothly but never exactly zero ‚Äî good for handling multicollinearity.\n",
        "\n",
        "Elastic Net: A combination of L1 and L2 ‚Äî useful when there are many correlated features.\n",
        "\n",
        "7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        "Use Elastic Net when:\n",
        "\n",
        "Features are highly correlated.\n",
        "\n",
        "You want both feature selection and model stability.\n",
        "\n",
        "Lasso alone might randomly pick one feature among correlated ones.\n",
        "\n",
        "8. What is the impact of the regularization parameter (Œª) in Logistic Regression?\n",
        "Œª (lambda) controls the strength of regularization.\n",
        "\n",
        "High Œª ‚Üí More regularization ‚Üí Simpler model (may underfit).\n",
        "\n",
        "Low Œª ‚Üí Less regularization ‚Üí Complex model (may overfit).\n",
        "\n",
        "9. What are the key assumptions of Logistic Regression?\n",
        "Linearity between independent variables and the log odds (not the dependent variable).\n",
        "\n",
        "No extreme multicollinearity.\n",
        "\n",
        "Observations are independent.\n",
        "\n",
        "Large sample size preferred for stable estimates.\n",
        "\n",
        "10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "Decision Trees\n",
        "\n",
        "Random Forest\n",
        "\n",
        "Support Vector Machines (SVM)\n",
        "\n",
        "Gradient Boosting (e.g., XGBoost)\n",
        "\n",
        "Neural Networks\n",
        "\n",
        "K-Nearest Neighbors (KNN)\n",
        "\n",
        "11. What are Classification Evaluation Metrics?\n",
        "Accuracy\n",
        "\n",
        "Precision\n",
        "\n",
        "Recall\n",
        "\n",
        "F1 Score\n",
        "\n",
        "ROC-AUC\n",
        "\n",
        "Confusion Matrix\n",
        "\n",
        "Log Loss\n",
        "\n",
        "12. How does class imbalance affect Logistic Regression?\n",
        "The model may become biased towards the majority class.\n",
        "\n",
        "Can lead to poor performance on the minority class.\n",
        "\n",
        "Solutions: Use class weights, oversampling (SMOTE), undersampling.\n",
        "\n",
        "13. What is Hyperparameter Tuning in Logistic Regression?\n",
        "Selecting the best hyperparameters (like Œª, penalty type, solver) to optimize model performance.\n",
        "\n",
        "Done using Grid Search, Random Search, or Bayesian Optimization.\n",
        "\n",
        "14. What are different solvers in Logistic Regression? Which one should be used?\n",
        "liblinear: Good for small datasets, supports L1 and L2.\n",
        "\n",
        "newton-cg: Good for L2 penalty, large datasets.\n",
        "\n",
        "sag: Faster for large datasets, only supports L2.\n",
        "\n",
        "saga: Supports L1, L2, and Elastic Net; good for large datasets.\n",
        "\n",
        "Choice:\n",
        "\n",
        "Small dataset ‚Üí liblinear\n",
        "\n",
        "Large dataset ‚Üí saga\n",
        "\n",
        "15. How is Logistic Regression extended for multiclass classification?\n",
        "One-vs-Rest (OvR): One classifier per class vs all others.\n",
        "\n",
        "Softmax (Multinomial Logistic Regression): Generalizes logistic regression for multiple classes directly.\n",
        "\n",
        "16. What are the advantages and disadvantages of Logistic Regression?\n",
        "Advantages:\n",
        "\n",
        "Simple and fast.\n",
        "\n",
        "Interpretable coefficients.\n",
        "\n",
        "Works well when the classes are linearly separable.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Struggles with non-linear problems.\n",
        "\n",
        "Sensitive to outliers.\n",
        "\n",
        "Assumes independence between features.\n",
        "\n",
        "17. What are some use cases of Logistic Regression?\n",
        "Email spam detection.\n",
        "\n",
        "Credit scoring.\n",
        "\n",
        "Disease diagnosis (e.g., diabetes prediction).\n",
        "\n",
        "Customer churn prediction.\n",
        "\n",
        "Marketing campaign response prediction.\n",
        "\n",
        "18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "Logistic Regression: Used for binary classification.\n",
        "\n",
        "Softmax Regression: Used for multi-class classification, outputs probabilities for each class.\n",
        "\n",
        "19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "If speed and simplicity are needed ‚Üí OvR.\n",
        "\n",
        "If better probability estimation and full class consideration are needed ‚Üí Softmax.\n",
        "\n",
        "20. How do we interpret coefficients in Logistic Regression?\n",
        "Each coefficient represents the change in the log-odds of the outcome for a one-unit increase in the predictor, holding all other predictors constant.\n",
        "\n",
        "Exponentiating a coefficient gives the odds ratio.\n",
        "\n",
        "\"\"\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Practical\n",
        "\n",
        "#1. Load dataset, split, train Logistic Regression, print accuracy\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm8J0KC0cRAK",
        "outputId": "acf7291e-67df-4358-8f86-049ac298d081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Apply L1 regularization (Lasso)\n",
        "\n",
        "model = LogisticRegression(penalty='l1', solver='saga', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy with L1 regularization:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIn27YPfdH-k",
        "outputId": "ee857eac-261d-40b5-b1b5-91435ad4d326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with L1 regularization: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Train with L2 regularization (Ridge)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy with L2 regularization:\", model.score(X_test, y_test))\n",
        "print(\"Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xuaepOmdN9W",
        "outputId": "73153ee0-f16e-49aa-909f-6041aa2403b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with L2 regularization: 1.0\n",
            "Coefficients: [[-0.40538546  0.86892246 -2.2778749  -0.95680114]\n",
            " [ 0.46642685 -0.37487888 -0.18745257 -0.72127133]\n",
            " [-0.06104139 -0.49404358  2.46532746  1.67807247]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Train Logistic Regression with Elastic Net\n",
        "\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy with Elastic Net:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCtwWtAMdSSO",
        "outputId": "70e29e16-b567-48db-8332-ccb226531dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Elastic Net: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Multiclass Logistic Regression using OvR\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"OvR Accuracy:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e1om11YdXL6",
        "outputId": "3e81a809-28fa-4ad2-c002-83e26c9a04c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvR Accuracy: 0.9555555555555556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Apply GridSearchCV to tune C and penalty\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best accuracy:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngnNx3ledb0a",
        "outputId": "a040e622-4cf5-4a8c-a6c1-02668ba275e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Best accuracy: 0.9619047619047618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Evaluate using Stratified K-Fold\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "scores = cross_val_score(model, X, y, cv=skf)\n",
        "\n",
        "print(\"Average Stratified K-Fold Accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH1W1KL5dhYM",
        "outputId": "09394f38-43de-4771-cca8-1f35e80c836c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Stratified K-Fold Accuracy: 0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Load dataset from CSV and apply Logistic Regression\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder # Import LabelEncoder\n",
        "\n",
        "\n",
        "df = pd.read_csv('/dev/CSV/amazon1.csv')\n",
        "# Check for the actual name of the target column\n",
        "print(df.columns)  # Print the column names to identify the target column\n",
        "\n",
        "# Replace 'review_score' with the actual target column name from the printed columns\n",
        "target_column_name = 'target Rate' # Example: 'rating'\n",
        "\n",
        "X = df.drop(target_column_name, axis=1)\n",
        "y = df[target_column_name]\n",
        "\n",
        "# Identify columns with non-numeric data\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create a LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply label encoding to each categorical column\n",
        "for col in categorical_cols:\n",
        "    X[col] = label_encoder.fit_transform(X[col])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Accuracy:\", model.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MvksWiWdnme",
        "outputId": "fa4d2b2e-d351-4767-d620-82f5a81b0481"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['product_id', 'product_name', 'category', 'discounted_price',\n",
            "       'actual_price', 'discount_percentage', 'rating', 'target Rate',\n",
            "       'rating_count', 'about_product', 'user_id', 'user_name', 'review_id',\n",
            "       'review_title', 'review_content', 'img_link', 'product_link'],\n",
            "      dtype='object')\n",
            "Accuracy: 0.23863636363636365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Apply RandomizedSearchCV for tuning\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_dist = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
        "random_search = RandomizedSearchCV(LogisticRegression(max_iter=1000), param_distributions=param_dist, cv=5, n_iter=5)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "print(\"Best accuracy:\", random_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ6lOAbDwapr",
        "outputId": "27e2d22c-25bb-4df2-a71a-857ff9b83f9f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1}\n",
            "Best accuracy: 0.24292682926829268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required package using the appropriate Colab command\n",
        "\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "ovo_model = OneVsOneClassifier(LogisticRegression(max_iter=1000))\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"OvO Accuracy:\", ovo_model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "U_zdWC_RwrHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11. Visualize confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()\n",
        "#11. Visualize confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt  # Import pyplot\n",
        "\n",
        "# ... (rest of your code) ...\n",
        "\n",
        "# Before plotting, set the font family to a known available font on your system\n",
        "plt.rcParams['font.family'] = 'Arial'  # Or any other font you have installed\n",
        "\n",
        "# Now try to plot the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()\n",
        "plt.show()  # Display the plot"
      ],
      "metadata": {
        "id": "1n6XXdLnyMPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12. Evaluate using Precision, Recall, and F1-Score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N99bi7lyka5",
        "outputId": "a9e6fdc4-daf2-4c61-aae1-b0276671c1cd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.24567056314183247\n",
            "Recall: 0.23863636363636365\n",
            "F1 Score: 0.22957003984566463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#13. Train on imbalanced data using class weights\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy with class weights:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hRyt8XlypKR",
        "outputId": "8c16ca9c-5d4f-4c56-c76a-939bf872132d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with class weights: 0.19318181818181818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#14. Train on Titanic dataset, handle missing values\n",
        "\n",
        "df = pd.read_csv('titanic.csv')\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "X = df[['Pclass', 'Age', 'SibSp', 'Fare']]\n",
        "y = df['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Titanic dataset accuracy:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "T7ydo-i9ytrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15. Apply feature scaling before Logistic Regression\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Accuracy with scaling:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMy4_yCczIW3",
        "outputId": "1a211970-9866-4f38-bc89-43213e08a721"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with scaling: 0.5818181818181818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#16. Evaluate using ROC-AUC score\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n"
      ],
      "metadata": {
        "id": "DwaSxsz8zPfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17. Train with custom learning rate (C=0.5)\n",
        "\n",
        "model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Accuracy with C=0.5:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOLKv6iyzUtS",
        "outputId": "1dc932e6-7db7-48d2-835e-87ad9e42c4f8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 0.5295454545454545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#18. Identify important features\n",
        "\n",
        "feature_importance = pd.Series(model.coef_[0], index=df.columns[:-1])\n",
        "print(\"Feature Importance:\\n\", feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH2orjUTzZkC",
        "outputId": "148285eb-f3e7-46f2-8be5-4387fd6fd220"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance:\n",
            " product_id             0.008829\n",
            "product_name          -0.200362\n",
            "category               0.422459\n",
            "discounted_price      -0.244244\n",
            "actual_price          -0.149932\n",
            "discount_percentage   -0.491425\n",
            "rating                 1.480221\n",
            "target Rate            0.576105\n",
            "rating_count           0.017573\n",
            "about_product          0.226476\n",
            "user_id               -0.249185\n",
            "user_name             -0.071216\n",
            "review_id             -0.416970\n",
            "review_title          -0.399488\n",
            "review_content         0.273859\n",
            "img_link              -0.183259\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#19. Evaluate using Cohen‚Äôs Kappa Score\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "print(\"Cohen's Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8M7_s0FzeDb",
        "outputId": "0d5d4032-b4a8-49a2-e9c5-11d937082afe"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.01713946234962127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#20. Visualize Precision-Recall Curve\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "PrecisionRecallDisplay(precision=precision, recall=recall).plot()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1nAagSJczi_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Train with different solvers and compare accuracy\n",
        "\n",
        "for solver in ['liblinear', 'saga', 'lbfgs']:\n",
        "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"Accuracy with {solver}: {model.score(X_test, y_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MVnZ4r4zoU7",
        "outputId": "3557fcb4-88fe-44e9-dc77-241e2de9ac47"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with liblinear: 0.3409090909090909\n",
            "Accuracy with saga: 0.5818181818181818\n",
            "Accuracy with lbfgs: 0.5818181818181818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Evaluate using Matthews Correlation Coefficient (MCC)\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "print(\"MCC Score:\", matthews_corrcoef(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKcb97GQzvHQ",
        "outputId": "70069ec1-764a-4455-ee20-b327c8030670"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC Score: 0.01731363428223641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Train on raw vs standardized data and compare\n",
        "\n",
        "# Raw data\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "raw_acc = model_raw.score(X_test, y_test)\n",
        "\n",
        "# Standardized data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "scaled_acc = model_scaled.score(X_test_scaled, y_test)\n",
        "\n",
        "print(\"Raw accuracy:\", raw_acc)\n",
        "print(\"Scaled accuracy:\", scaled_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbKpnExrzzFt",
        "outputId": "4a1105e3-a8b8-455e-d008-2437ffe271e4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw accuracy: 0.5818181818181818\n",
            "Scaled accuracy: 0.5136363636363637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24. Find optimal C using cross-validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "Cs = [0.01, 0.1, 1, 10, 100]\n",
        "best_c = 0\n",
        "best_score = 0\n",
        "\n",
        "for c in Cs:\n",
        "    model = LogisticRegression(C=c, max_iter=1000)\n",
        "    score = cross_val_score(model, X, y, cv=5).mean()\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_c = c\n",
        "\n",
        "print(f\"Best C: {best_c}, Best Score: {best_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GGg2OOlHz4ic",
        "outputId": "0c532f94-e029-41c5-80b8-451fc8c54a40"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C: 0.1, Best Score: 0.22457337883959044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Save and load Logistic Regression model using joblib\n",
        "\n",
        "import joblib\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, 'logistic_model.pkl')\n",
        "\n",
        "# Load model\n",
        "loaded_model = joblib.load('logistic_model.pkl')\n",
        "print(\"Loaded model accuracy:\", loaded_model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgs-04Qk0Ljl",
        "outputId": "e1f7dadd-fb7e-40f9-85f4-19dc2e7a3fd5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model accuracy: 0.16136363636363638\n"
          ]
        }
      ]
    }
  ]
}